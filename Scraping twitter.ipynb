{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from requests_html import HTMLSession, HTML\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "\n",
    "def get_tweets(user, pages=25):\n",
    "    \"\"\"Gets tweets for a given user, via the Twitter frontend API.\"\"\"\n",
    "\n",
    "    url = f'https://twitter.com/i/profiles/show/{user}/timeline/tweets?include_available_features=1&include_entities=1&include_new_items_bar=true'\n",
    "    headers = {\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Referer': f'https://twitter.com/{user}',\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8',\n",
    "        'X-Twitter-Active-User': 'yes',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "    \n",
    "    amountPages = pages\n",
    "\n",
    "    def gen_tweets(pages):\n",
    "        r = session.get(url, headers=headers)\n",
    "\n",
    "        while pages > 0:\n",
    "            status = 'ok'\n",
    "            try:\n",
    "                html = HTML(html=r.json()['items_html'], url='bunk', default_encoding='utf-8')\n",
    "            except:\n",
    "                # let other errors raise\n",
    "                status = 'page not found'\n",
    "            \n",
    "            comma = \",\"\n",
    "            dot = \".\"\n",
    "            tweets = []\n",
    "            for tweet in html.find('.stream-item'):\n",
    "                try:\n",
    "                  text = tweet.find('.tweet-text')[0].full_text\n",
    "                except:\n",
    "                  continue\n",
    "                tweetId = tweet.find(\n",
    "                    '.js-permalink')[0].attrs['data-conversation-id']\n",
    "                timestamp = datetime.fromtimestamp(\n",
    "                    int(tweet.find('._timestamp')[0].attrs['data-time-ms'])/1000.0)\n",
    "                interactions = [x.text for x in tweet.find(\n",
    "                    '.ProfileTweet-actionCount')]\n",
    "                replies = int(interactions[0].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                retweets = int(interactions[1].split(\" \")[\n",
    "                               0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                likes = int(interactions[2].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                hashtags = [hashtag_node.full_text for hashtag_node in tweet.find('.twitter-hashtag')]\n",
    "                urls = [url_node.attrs['data-expanded-url'] for url_node in tweet.find('a.twitter-timeline-link:not(.u-hidden)')]\n",
    "                photos = [photo_node.attrs['data-image-url'] for photo_node in tweet.find('.AdaptiveMedia-photoContainer')]\n",
    "                \n",
    "                videos = []\n",
    "                video_nodes = tweet.find(\".PlayableMedia-player\")\n",
    "                for node in video_nodes:\n",
    "                    styles = node.attrs['style'].split()\n",
    "                    for style in styles:\n",
    "                        if style.startswith('background'):\n",
    "                            tmp = style.split('/')[-1]\n",
    "                            video_id = tmp[:tmp.index('.jpg')]\n",
    "                            videos.append({'id': video_id})\n",
    "                tweets.append({'tweetId': tweetId, 'time': timestamp, 'text': text,\n",
    "                               'replies': replies, 'retweets': retweets, 'likes': likes, \n",
    "                               'entries': {\n",
    "                                    'hashtags': hashtags, 'urls': urls,\n",
    "                                    'photos': photos, 'videos': videos\n",
    "                                }\n",
    "                               })\n",
    "\n",
    "            last_tweet = html.find('.stream-item')[-1].attrs['data-item-id']\n",
    "\n",
    "            for tweet in tweets:\n",
    "                if tweet:\n",
    "                    tweet['text'] = re.sub('http', ' http', tweet['text'], 1)\n",
    "                    yield {'tweet': tweet, 'status': status }\n",
    "\n",
    "            r = session.get(\n",
    "                url, params = {'max_position': last_tweet}, headers = headers)\n",
    "            pages += -1\n",
    "            print('progress:', (amountPages-pages)/amountPages * 100, '%')\n",
    "\n",
    "    yield from gen_tweets(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from twitter_scraper_helmi import get_tweets\n",
    "\n",
    "data = []\n",
    "error = 0\n",
    "for t in get_tweets('gojekindonesia', pages=10):\n",
    "    data.append(t)\n",
    "    if (t['status'] != 'ok'):\n",
    "        error += 1\n",
    "    \n",
    "print('tweet found: ', len(data))\n",
    "print('error: ', error)\n",
    "\n",
    "for i, t in enumerate(data):\n",
    "    print(t['tweet']['text'], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
